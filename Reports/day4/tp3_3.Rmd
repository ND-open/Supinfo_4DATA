---
title: "TP3 Exercise 3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 3 : Classification

We are working on the “Spam” database which contains 4601 emails, which have been manually classified as Spam or Non-Spam. This database also contains 57 characteristics for each email (frequency of the words "money", "free", "credit", etc.). The objective is to develop an automatic classification algorithm, which, from the 57 characteristics, can decide whether a new mail should be classified as Spam or as Non-Spam.

The database can be downloaded here

https://archive.ics.uci.edu/ml/datasets/spambase (Links to an external site.)

1 - Download and save the files in your working directory.
2 - To import it into RStudio,

```{r data load}
library(pacman)
p_load(here)
p_load(tidyverse)

spambase <- read.csv(here::here("data-raw", "spambase.data") )

names(spambase) <- c(read.delim(here::here("data-raw", "spambase.names"), 
           header = FALSE, sep = ":", skip = 33,
           stringsAsFactors = FALSE)$V1, "spam")

names(spambase)
```


3 - Display the first lines of the database

```{r head of data}
spambase %>% 
        # select(`char_freq_#`) %>% 
        head(6)
```

```{r data glimpse}
spambase %>%  
        glimpse()
```


4 - Represent the database graphically, for example with a graph of this type:

```{r ggplot}
# library(ggplot2)
spambase %>% names()

spambase %>% 
        mutate(spam = factor(spam)) %>% 
        ggplot(aes(x = `char_freq_$` , y = word_freq_hp, colour = spam)) +
        geom_point(alpha = .5) +
        # geom_bar
        labs(title = "Spam vs frequences of free and hp",
             subtitle = "From the UCLI dataset",
             x = "Frequence of dollar",
             y = "Frequence of hp",
             caption = "Spam detection 4Data"
        ) +
        theme_light()
# theme_dark()
        # xlab("Frequence of dollar") + 
        # ylab("Frequence of hp") +
        # ggtitle("Spam vs frequences of free and hp")
```


5 - We will apply a logistic regression to predict the probability that an email is spam. The algorithm used to calculate the coefficients of the logistic model is programmed in the function

Glm with R.

We enter the variable to be explained (spam) as a function of explanatory variables.
(a) With two explanatory variables, the syntax is:

```{r}
spam_clean <- spambase %>% 
        mutate(spam = factor(spam))
```

```{r}
?glm
```

 res<-glm(as.factor(spam) wordfreqmake+wordfreqaddress,data=spambase, family="binomial")summary(res)

(b) When using the set of variables to predict the variable to be explained, the syntax is:

resC<-glm(as.factor(spam) .,data=spambase, family="binomial")summary(resC)

(c) We then apply an automatic variable selection method to keep only those that are relevant:

final<-step(resC)summary(final)

The selected variables can be interpreted by the expert.

